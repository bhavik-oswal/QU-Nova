{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LOfdREyCfHDe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dir = 'imgs'\n",
        "os.makedirs(plot_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "XWC0udO5fcWr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration (same as before)\n",
        "dataset_name = 'mnist'\n",
        "img_size = 28\n",
        "n_channels = 1\n",
        "img_coords = 2\n",
        "lr = 1e-4\n",
        "batch_size = 64\n",
        "num_latent = 32\n",
        "hidden_features = 256\n",
        "num_layers = 4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "cWbHZUbPfgkj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW: Mask parameters\n",
        "mask_type = 'center'  # 'center' or 'random'\n",
        "mask_size = 8  # For center mask\n"
      ],
      "metadata": {
        "id": "lKtHvJM4flms"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SIREN Model (same as before)\n",
        "class SirenLayer(nn.Module):\n",
        "    def __init__(self, in_f, out_f, w0=30, is_first=False, is_last=False):\n",
        "        super().__init__()\n",
        "        self.in_f = in_f\n",
        "        self.w0 = w0\n",
        "        self.linear = nn.Linear(in_f, out_f)\n",
        "        self.is_first = is_first\n",
        "        self.is_last = is_last\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        b = 1 / self.in_f if self.is_first else np.sqrt(6 / self.in_f) / self.w0\n",
        "        with torch.no_grad():\n",
        "            self.linear.weight.uniform_(-b, b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x if self.is_last else torch.sin(self.w0 * x)\n",
        "\n",
        "def gon_model(dimensions):\n",
        "    layers = [SirenLayer(dimensions[0], dimensions[1], is_first=True)]\n",
        "    for i in range(1, len(dimensions)-2):\n",
        "        layers.append(SirenLayer(dimensions[i], dimensions[i+1]))\n",
        "    layers.append(SirenLayer(dimensions[-2], dimensions[-1], is_last=True))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "GtGrYdr9fpGx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW: Mask creation function\n",
        "def create_mask(batch_size, img_size):\n",
        "    if mask_type == 'center':\n",
        "        mask = torch.ones(batch_size, img_size, img_size, 1)\n",
        "        c = img_size//2\n",
        "        mask[:, c-mask_size//2:c+mask_size//2, c-mask_size//2:c+mask_size//2, :] = 0\n",
        "    elif mask_type == 'random':\n",
        "        mask = torch.rand(batch_size, img_size, img_size, 1) > 0.25\n",
        "        mask = mask.float()\n",
        "    return mask.reshape(batch_size, -1, 1).to(device)"
      ],
      "metadata": {
        "id": "T1iVCmKmfw6u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions (same as before)\n",
        "def get_mgrid(sidelen, dim=2):\n",
        "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
        "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
        "    return mgrid.reshape(-1, dim)"
      ],
      "metadata": {
        "id": "B5sOgDD6fzA8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and model setup\n",
        "dataset = torchvision.datasets.MNIST('data', train=True, download=True,\n",
        "                                           transform=torchvision.transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "gon_shape = [img_coords+num_latent] + [hidden_features]*num_layers + [n_channels]\n",
        "F = gon_model(gon_shape).to(device)\n",
        "optim = torch.optim.Adam(F.parameters(), lr=lr)\n",
        "c = get_mgrid(img_size, 2).repeat(batch_size, 1, 1).to(device)  # Coordinates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2h9aLhvf2D9",
        "outputId": "868bca3b-ade6-4394-8265-8d75d9885f31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with inpainting\n",
        "for step in range(1001):\n",
        "    # Get batch and create masked version\n",
        "    x, _ = next(iter(train_loader))\n",
        "    x = x.permute(0, 2, 3, 1).reshape(batch_size, -1, n_channels).to(device)\n",
        "    mask = create_mask(batch_size, img_size)  # NEW: Create mask\n",
        "    x_masked = x * mask  # NEW: Apply mask\n",
        "\n",
        "    # Inner loop: Find z using MASKED pixels\n",
        "    z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    z_rep = z.repeat(1, c.size(1), 1)\n",
        "    g = F(torch.cat((c, z_rep), dim=-1))\n",
        "    L_inner = ((g - x_masked)**2 * mask).sum() / mask.sum()  # NEW: Masked loss\n",
        "    z = -torch.autograd.grad(L_inner, z, create_graph=True)[0]\n",
        "\n",
        "    # Outer loop: Reconstruct FULL image\n",
        "    z_rep = z.repeat(1, c.size(1), 1)\n",
        "    g = F(torch.cat((c, z_rep), dim=-1))\n",
        "    L_outer = ((g - x)**2).mean()\n",
        "\n",
        "    optim.zero_grad()\n",
        "    L_outer.backward()\n",
        "    optim.step()\n",
        "\n",
        "    # Save visualizations\n",
        "    if step % 100 == 0:\n",
        "        with torch.no_grad():\n",
        "            # Get example from first batch element\n",
        "            example_idx = 0\n",
        "            masked = x_masked[example_idx].reshape(img_size, img_size, 1)\n",
        "            reconstructed = g[example_idx].reshape(img_size, img_size, 1)\n",
        "\n",
        "            # Create side-by-side plot\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "            ax1.imshow(masked.cpu().numpy(), cmap='gray')\n",
        "            ax1.set_title('Masked Input')\n",
        "            ax2.imshow(reconstructed.cpu().numpy(), cmap='gray')\n",
        "            ax2.set_title('Reconstruction')\n",
        "            plt.savefig(f'imgs/inpaint_{step}.png')\n",
        "            plt.close()\n",
        "\n",
        "        print(f'Step {step}, Loss: {L_outer.item():.4f}')\n",
        "\n",
        "print(\"Training complete! Check 'imgs/' for inpainting results!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNcr5RnGf-Up",
        "outputId": "9f6e1dfb-8197-4c4c-d4c4-fe7ac9ecfa19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 0.1253\n",
            "Step 100, Loss: 0.0542\n",
            "Step 200, Loss: 0.0543\n",
            "Step 300, Loss: 0.0539\n",
            "Step 400, Loss: 0.0525\n",
            "Step 500, Loss: 0.0532\n",
            "Step 600, Loss: 0.0566\n",
            "Step 700, Loss: 0.0548\n",
            "Step 800, Loss: 0.0552\n",
            "Step 900, Loss: 0.0537\n",
            "Step 1000, Loss: 0.0520\n",
            "Training complete! Check 'imgs/' for inpainting results!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c2IeS6n9gNZf"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}