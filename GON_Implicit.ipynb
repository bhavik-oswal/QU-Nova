{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_LsmHo_JHqLd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dir = 'imgs'\n",
        "os.makedirs(plot_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "O2vzP47mHxgW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image data\n",
        "dataset_name = 'mnist' # ['mnist', 'fashion']\n",
        "img_size = 28\n",
        "n_channels = 1\n",
        "img_coords = 2\n",
        "\n",
        "# training info\n",
        "lr = 1e-4\n",
        "batch_size = 64\n",
        "num_latent = 32\n",
        "hidden_features = 256\n",
        "num_layers = 4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TboSsB5RLM_j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SirenLayer(nn.Module):\n",
        "    def __init__(self, in_f, out_f, w0=30, is_first=False, is_last=False):\n",
        "        super().__init__()\n",
        "        self.in_f = in_f\n",
        "        self.w0 = w0\n",
        "        self.linear = nn.Linear(in_f, out_f)\n",
        "        self.is_first = is_first\n",
        "        self.is_last = is_last\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        b = 1 / self.in_f if self.is_first else np.sqrt(6 / self.in_f) / self.w0\n",
        "        with torch.no_grad():\n",
        "            self.linear.weight.uniform_(-b, b)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x if self.is_last else torch.sin(self.w0 * x)\n",
        "\n",
        "def gon_model(dimensions):\n",
        "    first_layer = SirenLayer(dimensions[0], dimensions[1], is_first=True)\n",
        "    other_layers = []\n",
        "    for dim0, dim1 in zip(dimensions[1:-2], dimensions[2:-1]):\n",
        "        other_layers.append(SirenLayer(dim0, dim1))\n",
        "    final_layer = SirenLayer(dimensions[-2], dimensions[-1], is_last=True)\n",
        "    return nn.Sequential(first_layer, *other_layers, final_layer)\n",
        "\n",
        "# helper functions\n",
        "def get_mgrid(sidelen, dim=2):\n",
        "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
        "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
        "    mgrid = mgrid.reshape(-1, dim)\n",
        "    return mgrid\n",
        "\n",
        "def cycle(iterable):\n",
        "    while True:\n",
        "        for x in iterable:\n",
        "            yield x\n",
        "\n",
        "def slerp(a, b, t):\n",
        "    omega = torch.acos((a/torch.norm(a, dim=1, keepdim=True)*b/torch.norm(b, dim=1, keepdim=True)).sum(1)).unsqueeze(1)\n",
        "    res = (torch.sin((1.0-t)*omega)/torch.sin(omega))*a + (torch.sin(t*omega)/torch.sin(omega)) * b\n",
        "    return res\n",
        "\n",
        "def slerp_batch(model, z, coords):\n",
        "    lz = z.data.clone().squeeze(1)\n",
        "    col_size = int(np.sqrt(z.size(0)))\n",
        "    src_z = lz.data[:col_size].repeat(col_size,1)\n",
        "    z1, z2 = lz.data.split(lz.shape[0]//2)\n",
        "    tgt_z = torch.cat([z2, z1])\n",
        "    tgt_z = tgt_z[:col_size].repeat(col_size,1)\n",
        "    t = torch.linspace(0,1,col_size).unsqueeze(1).repeat(1,col_size).contiguous().view(batch_size,1).contiguous().to(device)\n",
        "    z_slerp = slerp(src_z, tgt_z, t)\n",
        "    z_slerp_rep = z_slerp.unsqueeze(1).repeat(1,coords.size(1),1)\n",
        "    g_slerp = model(torch.cat((coords, z_slerp_rep), dim=-1))\n",
        "    return g_slerp\n",
        "\n",
        "def gon_sample(model, recent_zs, coords):\n",
        "    zs = torch.cat(recent_zs, dim=0).squeeze(1).cpu().numpy()\n",
        "    mean = np.mean(zs, axis=0)\n",
        "    cov = np.cov(zs.T)\n",
        "    sample = np.random.multivariate_normal(mean, cov, size=batch_size)\n",
        "    sample = torch.tensor(sample).unsqueeze(1).repeat(1,coords.size(1),1).to(device).float()\n",
        "    model_input = torch.cat((coords, sample), dim=-1)\n",
        "    return model(model_input)"
      ],
      "metadata": {
        "id": "Eh8ecr4NLR2P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load datasets\n",
        "if dataset_name == 'mnist':\n",
        "    dataset = torchvision.datasets.MNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "if dataset_name == 'fashion':\n",
        "    dataset = torchvision.datasets.FashionMNIST('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, sampler=None, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "train_iterator = iter(cycle(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obgl79jvLZfp",
        "outputId": "4e1f644e-4378-410f-8381-36effcdf9358"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 610kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.83MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.53MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define GON architecture, for example gon_shape = [34, 256, 256, 256, 256, 1]\n",
        "gon_shape = [img_coords+num_latent] + [hidden_features]*num_layers + [n_channels]\n",
        "F = gon_model(gon_shape).to(device)\n",
        "\n",
        "optim = torch.optim.Adam(lr=lr, params=F.parameters())\n",
        "c = torch.stack([get_mgrid(img_size, 2) for _ in range(batch_size)]).to(device) # coordinates\n",
        "print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(F.parameters()))}')\n",
        "\n",
        "recent_zs = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iddL4sJLdET",
        "outputId": "7e337a0d-3dcf-4754-87a9-25b59d8a0825"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Number of parameters 206593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(501):\n",
        "    # sample a batch of data\n",
        "    x, t = next(train_iterator)\n",
        "    x, t = x.to(device), t.to(device)\n",
        "    x = x.permute(0, 2, 3, 1).reshape(batch_size, -1, n_channels)\n",
        "\n",
        "    # compute the gradients of the inner loss with respect to zeros (gradient origin)\n",
        "    z = torch.zeros(batch_size, 1, num_latent).to(device).requires_grad_()\n",
        "    z_rep = z.repeat(1,c.size(1),1)\n",
        "    g = F(torch.cat((c, z_rep), dim=-1))\n",
        "    L_inner = ((g - x)**2).sum(1).mean()\n",
        "    z = -torch.autograd.grad(L_inner, [z], create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    # now with z as our new latent points, optimise the data fitting loss\n",
        "    z_rep = z.repeat(1, c.size(1), 1)\n",
        "    g = F(torch.cat((c, z_rep), dim=-1))\n",
        "    L_outer = ((g - x)**2).sum(1).mean()\n",
        "    optim.zero_grad()\n",
        "    L_outer.backward()\n",
        "    optim.step()\n",
        "\n",
        "    # compute sampling statistics\n",
        "    recent_zs.append(z.detach())\n",
        "    recent_zs = recent_zs[-100:]\n",
        "\n",
        "    if step % 100 == 0 and step > 0:\n",
        "        print(f\"Step: {step}   Loss: {L_outer.item():.3f}\")\n",
        "\n",
        "        # plot reconstructions\n",
        "        torchvision.utils.save_image(torch.clamp(g, 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size),\n",
        "            f'imgs/recon_{step}.png', nrow=int(np.sqrt(batch_size)), padding=0)\n",
        "\n",
        "        # plot interpolations\n",
        "        torchvision.utils.save_image(torch.clamp(slerp_batch(F, z.data, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size),\n",
        "            f'imgs/slerp_{step}.png', nrow=int(np.sqrt(batch_size)), padding=0)\n",
        "\n",
        "        # plot samples\n",
        "        torchvision.utils.save_image(torch.clamp(gon_sample(F, recent_zs, c), 0, 1).permute(0,2,1).reshape(-1, n_channels, img_size, img_size),\n",
        "            f'imgs/sample_{step}.png', nrow=int(np.sqrt(batch_size)), padding=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQcL_JIpLhne",
        "outputId": "58d0ec98-1071-4504-f7df-f5e2e5de6a87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 100   Loss: 26.910\n",
            "Step: 200   Loss: 18.439\n",
            "Step: 300   Loss: 16.047\n",
            "Step: 400   Loss: 15.281\n",
            "Step: 500   Loss: 11.114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2KRWbyWkLkcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}